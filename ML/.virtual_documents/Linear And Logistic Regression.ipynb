import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


hp = pd.read_csv('House Prices - Reg.csv')


train, test=train_test_split(hp, test_size=0.3,random_state=123)


hp.shape, train.shape, test.shape


X = hp.drop(columns= 'Price')
y=hp.Price


X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3,random_state=123)


from sklearn.preprocessing import StandardScaler


sc= StandardScaler()





X_train_std = sc.fit_transform(X_train)
X_test_std = sc.transform(X_test)


from sklearn.linear_model import LinearRegression, LogisticRegression


LR = LinearRegression()


LR.fit(X_train_std, y_train)


price_pred = LR.predict(X_test_std)


e = price_pred - y_test


np.mean(np.abs(e)) #Mean absolute error


np.mean(np.square(e)) #Mean absolute error


from sklearn.metrics import mean_absolute_error, mean_squared_error


mean_absolute_error(y_test, price_pred)


mean_squared_error(y_test, price_pred)


from sklearn.datasets import load_breast_cancer


lbc = load_breast_cancer()


bc = pd.DataFrame(lbc.data, columns = lbc.feature_names)


bc['target'] = lbc.target


print(lbc.DESCR)


bc.target.value_counts()


#212 - Malignant, 357 - Benign


#standardizaion
# StandardScaler()
X_bc = bc.drop(columns = 'target')
y_bc = bc.target
X_bc_train, X_bc_test, y_bc_train, y_bc_test =train_test_split(X_bc, y_bc, test_size=0.33,random_state=123)
scbc = StandardScaler()


X_bc_train_std = scbc.fit_transform(X_bc_train)
X_bc_test_std = scbc.transform(X_bc_test)


LGR = LogisticRegression(max_iter=5000)


LGR.fit(X_bc_train_std, y_bc_train)


cancer_pred = LGR.predict(X_bc_test_std)


err = pd.crosstab(y_bc_test, cancer_pred)


err


from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, roc_auc_score, roc_curve


accuracy_score(y_bc_test, cancer_pred)


from sklearn.linear_model import SGDClassifier, SGDRegressor 


SGDRegressor()


print(classification_report(y_bc_test, LGR.predict(X_bc_test_std)))


fpr, tpr, thresholds = roc_curve(y_bc_test, LGR.predict_proba(X_bc_test_std)[:,0], pos_label = 0)


plt.plot(fpr, tpr)
plt.show()


roc_auc_score(y_bc_test, LGR.predict_proba(X_bc_test_std)[:,1])


from sklearn.linear_model import SGDClassifier, SGDRegressor


sgd_class = SGDClassifier(loss='log')


sgd_class.fit(X_bc_train_std, y_bc_train)


sgd_class.predict(X_bc_test_std)


penalty = ['l2', 'l1', 'elasticnet']
alpha = [0.01, 1, 10, 100, 1000]
l1_ratio = [0, 1, 0.5, 0.2, 0.8]
learning_rate = ['constant', 'adaptive']
eta0 = [0.001, 0.01, 0.1, 0.02, 0.8, 0.08, 1, 10, 100]


from sklearn.model_selection import GridSearchCV, RandomizedSearchCV


 param_dist = dict(penalty=penalty, alpha=alpha, l1_ratio=l1_ratio, learning_rate=learning_rate, eta0=eta0)


sgd_logistic = SGDClassifier()


rndm_cv = RandomizedSearchCV(estimator=sgd_logistic, param_distributions=param_dist, n_iter=19, n_jobs=-1, verbose=2)


rndm_cv.fit(X_bc_train_std, y_bc_train)


rndm_cv.best_estimator_


rndm_cv.predict(X_bc_test_std)


print(classification_report(y_bc_test, rndm_cv.predict(X_bc_test_std)))


train_bc, test_bc = train_test_split(bc, test_size=0.1, random_state=123)


train_bc['kfold_tag'] = 9999


train_bc.head()


train_bc.groupby(['kfold_tag'])[['target']].count()


bc_cv = train_bc.sample(frac=1).reset_index(drop=True) # Shuffling the data


from sklearn.model_selection import KFold, StratifiedKFold


kf = KFold()


for fold, (train_indices, valid_indices) in enumerate (kf.split(bc_cv), start=1):
    # print(fold, (train_indices, valid_indices))
    bc_cv.loc[valid_indices, 'kfold_tag'] = fold


bc_cv.groupby(['kfold_tag'])[['target']].count()


skf_cv = StratifiedKFold()


bc_cv['skfold_tag'] = 9898


for fold, (train_indices, valid_indices) in enumerate (skf_cv.split(bc_cv, y=bc_cv.target), start=1):
    #print(fold, (train_indices, valid_indices))
    bc_cv.loc[valid_indices, 'skfold_tag'] = fold


bc_cv.head(5)


bc_cv.groupby(['skfold_tag', 'target'])[['target']].count()


X_vars = [x_var for x_var in bc_cv.columns if x_var not in ['target', 'skfold_tag', 'kfold_tag']]


from sklearn.metrics import accuracy_score



final_pred = []
for fold in range(1,6):
    train = bc_cv[bc_cv.skfold_tag != fold]
    test = bc_cv[bc_cv.skfold_tag == fold]
    x_train = train[X_vars]
    y_train = train['target']
    x_test  = test[X_vars]
    y_test  = test['target']
    
    model = SGDClassifier()
    scbc = StandardScaler()
    x_train_std = scbc.fit_transform(x_train)
    x_test_std = scbc.transform(x_test)
    deply_X_data = scbc.transform(test_bc.drop(columns = 'target'))
    model.fit(x_train_std, y_train)
    pred_valid = model.predict(x_test_std)
    final_pred.append(model.predict(deply_X_data))
    print(fold)
    print('accuracy from fold = ', fold, 'score: ', accuracy_score(y_test, pred_valid))


final_pred


import numpy as np


np.sum(np.array(final_pred), axis=0)


(np.sum(np.array(final_pred), axis=0)>=3).astype('int')


 #Decision Trees
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
import matplotlib.pyplot as plt


dt = DecisionTreeClassifier()


train_bc.drop(columns = ['kfold_tag'], inplace=True)


dt.fit(train_bc.drop(columns='target'), train_bc.target)


fig = plt.figure(figsize=(100,50))
tree.plot_tree(dt, feature_names=list(train_bc.drop(columns='target')), filled = True, class_names=['Malignant', 'Benign'])
plt.show()
plt.savefig('dt.png')





dt = DecisionTreeClassifier(min_samples_split=100, min_samples_leaf=30)





dt.fit(train_bc.drop(columns='target'), train_bc.target)
fig = plt.figure(figsize=(100,50))
tree.plot_tree(dt, feature_names=list(train_bc.drop(columns='target')), filled = True, class_names=['Malignant', 'Benign'])
plt.show()
plt.savefig('dt.png')



