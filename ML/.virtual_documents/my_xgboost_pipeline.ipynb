import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb
from sklearn.model_selection import RandomizedSearchCV


# Load the data
housing = pd.read_excel('housing.xlsx')


num_cols = housing.select_dtypes(exclude='O').columns
cat_cols = housing.select_dtypes(include='O').columns


num_pipeline = Pipeline([('impute', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])


cat_pipeline = Pipeline([('oe', OneHotEncoder(handle_unknown='ignore'))])


preprocessing = ColumnTransformer([('num', num_pipeline, num_cols), ('cat', cat_pipeline, cat_cols)])

# preprocessor = ColumnTransformer(
#     transformers=[
#         ('num', numerical_pipeline, numerical_features),
#         ('cat', categorical_pipeline, categorical_features)
#     ])


# final_pipeline = Pipeline([('preproc', preprocessing), ('mdl', xgb.XGBRegressor())])
data_cleaned = preprocessing.fit_transform(housing)


data_cleaned


final_pipeline = Pipeline([('preprocess', preprocessing), ('xgb', xgb.XGBRegressor())])


final_pipeline.fit(housing, housing.median_house_value)


gbm_param = {
    'xgb__n_estimators': [40,50,60],
    'xgb__max_depth':[4,6,8],
    'xgb__learning_rate':[.4,.2,.5,.8],
    'xgb__colsample_bytree':[.01,.02,.03,.4,.5,.8]
}


xgb_rscv = RandomizedSearchCV(estimator=final_pipeline, scoring='neg_mean_squared_error', param_distributions=gbm_param, n_iter=20, n_jobs=-1)


xgb_rscv.fit(housing, housing.median_house_value)


xgb_rscv.get_params()


xgb_rscv.predict(housing)


from joblib import load, dump


dump(xgb_rscv, 'file_xgb_rscv.joblib')


saved_model = load('file_xgb_rscv.joblib')


saved_model.predict(housing)


import pickle


with open('pipeline_model', 'wb') as file:
    pickle.dump(xgb_rscv, file)


pwd()



